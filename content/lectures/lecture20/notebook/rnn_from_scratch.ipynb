{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title :\n",
    "RNN from scratch\n",
    "\n",
    "## Description :\n",
    "The aim of this exercise is to understand what happens within an RNN unit that is wrapped within the tensorflow.keras.layers.SimpleRNN\n",
    "\n",
    "The idea is to write a Recurrent Neural Network from scratch that generates names of dinosaurs by training on the existing names character-wise.\n",
    "\n",
    "## Instructions:\n",
    "- Read the file `dino.txt` and convert all the names in the files to lowercase.\n",
    "- Save the names in the file as a list.\n",
    "- Get the number of words in the file and the vocabulary size which is equal to the number of alphabets plus the newline character.\n",
    "- Define a dictionary `char_to_ix`  where the key is the sorted vocabulary and the value is the integer value assigned to it.\n",
    "- Define a dictionary `ix_to_char`  where the key is the integer value assigned to the unique vocabulary and the value is the sorted vocabulary.\n",
    "- To get the model parameters (weights and biases) call the get_weights function twice once by:\n",
    "    - Setting the `random` parameter as 1 to get random weights\n",
    "    - Setting the `random` parameter as 0 to get the trained weights by specifying the number of iterations.\n",
    "- Define a function `rnn_model` that takes in the network parameters and outputs the generated dinosaur name based on the instructions in the scaffold.\n",
    "\n",
    "## Hints:\n",
    "\n",
    "$$h_t\\ =\\ \\tanh\\left(\\ Uh_{t-1}\\ +\\ Vx_t\\ +\\ \\beta_1\\right)$$\n",
    "\n",
    "$$Y_{t\\ }\\ =\\ \\sigma\\left(Wh_t\\ +\\ \\beta_2\\right)$$\n",
    "\n",
    "\n",
    "<a href=\"https://docs.python.org/3/library/functions.html#sorted\" target=\"_blank\">sorted()</a> Return a new sorted list from the items in iterable.\n",
    "\n",
    "<a href=\"https://book.pythontips.com/en/latest/enumerate.html\" target=\"_blank\">enumerate()</a> Allows to loop over something and have an automatic counter.\n",
    "\n",
    "<a href=\"https://docs.python.org/3/library/stdtypes.html?highlight=lower#str.lower\" target=\"_blank\">lower()</a> Return a copy of the string with all the cased characters converted to lowercase.\n",
    "\n",
    "<a href=\"https://docs.python.org/3/library/stdtypes.html?highlight=strip#str.strip\" target=\"_blank\">strip()</a> Return a copy of the string with the leading and trailing characters removed.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/random/generated/numpy.random.shuffle.html\" target=\"_blank\">np.random.shuffle()</a> Modify a sequence in-place by shuffling its contents.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.zeros.html?highlight=zeros#numpy.zeros\" target=\"_blank\">np.zeros()</a> Return a new array of given shape and type, filled with zeros.\n",
    "\n",
    "<a href=\"https://docs.python.org/3/library/stdtypes.html?highlight=join#str.join\" target=\"_blank\">join()</a> Return a string which is the concatenation of the strings in iterable.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.tanh.html?highlight=tanh#numpy.tanh\" target=\"_blank\">np.tanh()</a> Compute hyperbolic tangent element-wise.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.dot.html?highlight=dot#numpy.dot\" target=\"_blank\">np.dot()</a> Returns the dot product of two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "import numpy as np\n",
    "from helper import softmax, get_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the next set of characters which forms the dinosaur name\n",
    "def rnn_model(parameters, char_to_ix):\n",
    "\n",
    "    # Get the weights and biases from the parameters dictionary\n",
    "    U, V, W = parameters['U'], parameters['V'], parameters['W']\n",
    "    beta1, beta2 = parameters['beta1'], parameters['beta2']\n",
    "\n",
    "    # Get the size of the vocabulary i.e. 27\n",
    "    # One for each alphabet plus the new line character\n",
    "    vocab_size = beta2.shape[0]\n",
    "\n",
    "    # Get the size of the weights\n",
    "    n_h = U.shape[1]    \n",
    "\n",
    "    # Initialize the input as an array of zeroes with size as (vocab_size,1)\n",
    "    # This one-hot encodes the input\n",
    "    x = np.zeros((vocab_size,1))\n",
    "\n",
    "    # Initialize the inital hidden state as an array of zeroes with size as (n_h,1)    \n",
    "    h_prev = np.zeros((n_h, 1))\n",
    "\n",
    "    # Initialize a list to store the indices of the predicted characters\n",
    "    indices = []\n",
    "    \n",
    "    # Initialize an idx variable to hold the index values of the characters \n",
    "    idx = -1 \n",
    "    \n",
    "    # Initialize a counter to fix the maximum length of the predicted word\n",
    "    counter = 0\n",
    "\n",
    "    # Get the value of the new line from the char_to_ix dictionary\n",
    "    newline_character = char_to_ix['\\n']\n",
    "    \n",
    "    # Loop until the newline_character is predicted or until the max length of the word is 50\n",
    "    while (idx != newline_character and counter != 50):\n",
    "\n",
    "        # Compute the new state h of the RNN unit using the equation given in the instructions\n",
    "        # WRONG h = np.tanh(U * h_prev + V * x + beta1)\n",
    "        h = np.tanh(np.dot(U,h_prev) + np.dot(V, x) + beta1)\n",
    "\n",
    "        # Compute the output of the RNN unit using the equation \n",
    "        # given in the instructions using the softmax function\n",
    "        y = softmax(np.dot(W,h) + beta2)\n",
    "\n",
    "        # Get the index value of the predicted/generated character\n",
    "        # Instead of taking the argmax, we perform sampling on the probabilities \n",
    "        # got from the softmax function\n",
    "        idx = np.random.choice(list(range(vocab_size)), p=y.ravel())\n",
    "\n",
    "        # Append the index value to the indices list\n",
    "        indices.append(idx)\n",
    "        \n",
    "        # Initialize an array of with zeroes with size (vocab_size,1)\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "\n",
    "        # Set the idx position of x as 1.\n",
    "        # This will act as the output y and the next input. \n",
    "        x[idx] = 1\n",
    "        \n",
    "        # Update the previous state value with the current state\n",
    "        h_prev = h\n",
    "        \n",
    "        # Increment the counter\n",
    "        counter+=1\n",
    "    \n",
    "    # If the counter value reaches 50 append a newline character to the indices list\n",
    "    if (counter == 50):\n",
    "        indices.append(char_to_ix['\\n'])\n",
    "    \n",
    "    # Return the list of indices\n",
    "    return indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([\"b\", \"c\", \"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abs', 'cs', 'bs']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"abs\", \"bs\", \"cs\"]\n",
    "np.random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dinos.txt file\n",
    "data = open('../data/dinos.txt', 'r').read()\n",
    "\n",
    "# Convert the data to lower case\n",
    "data= data.lower()\n",
    "\n",
    "# Convert the file data into list\n",
    "chars = list(set(data))\n",
    "\n",
    "# Get length of the file and length of the vocabulary\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "\n",
    "# Define a dictionary with the sorted vocabulary as key and \n",
    "# value as a unique integer using enumerate\n",
    "char_to_ix = {a: b for b, a in enumerate(sorted(chars))}\n",
    "\n",
    "# Define a dictionary with the unique integers assigned to the sorted vocabulary as key\n",
    "# and value as a unique integer using enumerate\n",
    "ix_to_char = {a:b for a, b in enumerate(sorted(chars))}\n",
    "\n",
    "# Call the get_weights function to get the model weights\n",
    "# To get random weights set random=1\n",
    "# To get the trained weights specify the number of iterations and set random=0\n",
    "parameters = get_weights(num_iterations=20000, random=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50) (50, 27) (27, 50)\n"
     ]
    }
   ],
   "source": [
    "U, V, W = parameters['U'], parameters['V'], parameters['W']\n",
    "print(U.shape, V.shape, W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1) (27, 1)\n"
     ]
    }
   ],
   "source": [
    "beta1, beta2 = parameters['beta1'], parameters['beta2']\n",
    "print(beta1.shape, beta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ariilosaurus\n"
     ]
    }
   ],
   "source": [
    "# Call the predict function defined above passing \n",
    "# the parameters dictionary, char_to_ix dictionary\n",
    "sampled_indices = rnn_model(parameters, char_to_ix)\n",
    "\n",
    "# Convert the list of indices returned by the predict function to \n",
    "# their respective characters and then join to form a word\n",
    "txt = \"\".join([ix_to_char[index] for index in sampled_indices])\n",
    "\n",
    "# Captializing the first character\n",
    "txt = txt[0].upper() + txt[1:]  \n",
    "\n",
    "# Print the generated dinosaur name \n",
    "print('%s' % (txt, ), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ What do you observe from the generated names when the number of iterations in the get_weights function increase to 20,000 with random=0?\n",
    "\n",
    "#### A. The length of the names generated increases proportionately with the number of iterations.\n",
    "#### B. Insufficient storage because of large window size.\n",
    "#### C. The names generated are better due to longer training.\n",
    "#### D. Larger number of iterations causes the loss of the model to increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow1) ###\n",
    "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
    "answer1 = 'C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ What is the difference in the generated name from when the model is given random weights and trained weights?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow2) ###\n",
    "# Type your answer within in the quotes given\n",
    "answer2 = '___'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 19, 11, 5, 12, 5, 20, 15, 14]\n",
      "[19, 11, 5, 12, 5, 20, 15, 14, 0]\n",
      "[None, 6, 21, 20, 1, 2, 1, 19, 1, 21, 18, 21, 19]\n",
      "[6, 21, 20, 1, 2, 1, 19, 1, 21, 18, 21, 19, 0]\n",
      "[None, 16, 12, 1, 20, 25, 3, 5, 18, 1, 20, 15, 16, 19]\n",
      "[16, 12, 1, 20, 25, 3, 5, 18, 1, 20, 15, 16, 19, 0]\n",
      "[None, 1, 14, 20, 1, 18, 3, 20, 15, 19, 1, 21, 18, 21, 19]\n",
      "[1, 14, 20, 1, 18, 3, 20, 15, 19, 1, 21, 18, 21, 19, 0]\n",
      "[None, 15, 19, 13, 1, 11, 1, 19, 1, 21, 18, 21, 19]\n",
      "[15, 19, 13, 1, 11, 1, 19, 1, 21, 18, 21, 19, 0]\n",
      "[None, 5, 18, 11, 5, 20, 21]\n",
      "[5, 18, 11, 5, 20, 21, 0]\n",
      "[None, 1, 18, 3, 15, 22, 5, 14, 1, 20, 15, 18]\n",
      "[1, 18, 3, 15, 22, 5, 14, 1, 20, 15, 18, 0]\n",
      "[None, 7, 1, 19, 15, 19, 1, 21, 18, 21, 19]\n",
      "[7, 1, 19, 15, 19, 1, 21, 18, 21, 19, 0]\n",
      "[None, 20, 1, 16, 21, 9, 1, 19, 1, 21, 18, 21, 19]\n",
      "[20, 1, 16, 21, 9, 1, 19, 1, 21, 18, 21, 19, 0]\n",
      "[None, 14, 5, 13, 5, 7, 20, 9, 1]\n",
      "[14, 5, 13, 5, 7, 20, 9, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/dinos.txt\") as f:\n",
    "       examples = f.readlines()\n",
    "\n",
    "examples = [x.lower().strip() for x in examples]\n",
    "\n",
    "np.random.shuffle(examples)\n",
    "\n",
    "for j in range(10):\n",
    "    index = j % len(examples)\n",
    "    X = [None] + [char_to_ix[ch] for ch in examples[index]]\n",
    "    Y = X[1:] + [char_to_ix[\"\\n\"]]\n",
    "    print(X)\n",
    "    print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "h0 = np.zeros((10, 1))\n",
    "\n",
    "x, h, y_hat = {}, {}, {}\n",
    "h[-1] = np.copy(h0)\n",
    "loss = 0\n",
    "for t in range(len(X)):\n",
    "    x[t] = np.zeros((vocab_size, 1))\n",
    "    if (X[t] != None):\n",
    "        x[t][X[t]] = 1\n",
    "        print(x[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [-1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in reversed(range(10)):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
